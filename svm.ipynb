{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63332a2",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">SVM (Support Vector Machine)</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ed875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1bc35",
   "metadata": {},
   "source": [
    "## Входные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbfd5da",
   "metadata": {},
   "source": [
    "$2$-классовая $n$-мерная выборка размера $K$ с числовыми признаками. То есть полагаем, что все объекты выборки имеют вид:\n",
    "$$(x_1, x_2, \\dots, x_n, c)\\text{, где }c\\in\\{-1,1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8422ed3",
   "metadata": {},
   "source": [
    "## Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ed6a1",
   "metadata": {},
   "source": [
    "Хотим разделить выборку какой-то $(n-1)$-мерной гиперплоскостью, чтобы\n",
    "  1) по одну сторону от гиперплоскости лежали экземпляры первого класса, а по другую стороны экземпляры второго класса (в идеальном случае);\n",
    "\n",
    "  2) гиперплоскость была \"оптимальной\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae1b94",
   "metadata": {},
   "source": [
    "Какая прямая среди $L_1$, $L_2$ и $L_3$ лучше разделяет выборку?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4e57fa5",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Classifier.svg/1920px-Classifier.svg.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c8e14",
   "metadata": {},
   "source": [
    "_**Оптимальная разделяющая гиперплоскость**_ &ndash; такая гиперплоскость, у которой сумма расстояний до двух ближайших к ней точек, лежащих по разные стороны от неё, максимальна. Это определение следует из того, что мы полагаем, что максимизация зазора между классами способствует более уверенной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad41b9",
   "metadata": {},
   "source": [
    "Математически искомую гиперплоскость можно записать в следующем виде:\n",
    "$$l(\\mathbf{x})=\\mathbf{w}\\cdot \\mathbf{x} +b$$\n",
    "Тогда определить класс нового объекта становится просто:\n",
    "$$c(\\mathbf{x})=\\mathrm{sgn}(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "\n",
    "Таким образом, задача формулируется так: \"найти $\\mathbf{w}$ и $b$ такие, чтобы гиперплоскость $l(\\mathbf{x})=\\mathbf{w}\\cdot \\mathbf{x} +b$ была _**оптимальной разделяющей гиперплоскостью**_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae262b",
   "metadata": {},
   "source": [
    "## Математика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c623f8",
   "metadata": {},
   "source": [
    "### Случай линейно-разделимой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fba0ad",
   "metadata": {},
   "source": [
    "Назовём _**отступом**_ такое выражение (по сути &ndash; расстояние от точки до гиперплоскости по модулю):\n",
    "$$M_i=с_i\\cdot(\\mathbf{w}\\cdot\\mathbf{x}_i + b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca812030",
   "metadata": {},
   "source": [
    "Можно произвести нормировку отступов коэффициентом $\\alpha$:\n",
    "$$M_i=\\alpha \\cdot с_i\\cdot(\\mathbf{w}\\cdot\\mathbf{x}_i + b) = с_i\\cdot((\\alpha \\cdot\\mathbf{w})\\cdot\\mathbf{x}_i + (\\alpha \\cdot b))$$\n",
    "так, чтобы отступы ближайших к гиперплоскости точек были равны $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c000219",
   "metadata": {},
   "source": [
    "Таким образом, суть задачи не меняется &ndash; мы всё так же ищем вектор $(\\alpha \\cdot\\mathbf{w})$ и число $(\\alpha \\cdot b)$ (далее будем обозначать их просто как $\\mathbf{w}$ и $b$) так, чтобы чтобы гиперплоскость $l(\\mathbf{x})=\\mathbf{w}\\cdot \\mathbf{x} +b$ была _**оптимальной разделяющей гиперплоскостью**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8b03a",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/SVM_margins.svg/1920px-SVM_margins.svg.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e958c3",
   "metadata": {},
   "source": [
    "Через ближайшие к гиперплоскости точки можно провести полосу, ширина которой будет равна:\n",
    "$$\\mathrm{pr}_{\\mathbf{w}}\\left(\\mathbf{x_+}-\\mathbf{x_-}\\right)=\\left(\\mathbf{x_+}-\\mathbf{x_-}\\right)\\cdot \\frac{\\mathbf{w}}{\\lVert\\mathbf{w}\\rVert}=\\frac{\\mathbf{w}\\cdot\\mathbf{x_+} - \\mathbf{w}\\cdot\\mathbf{x_-}}{\\lVert\\mathbf{w}\\rVert}=\\frac{\\frac{M_+ - b}{c_+}-\\frac{M_- - b}{c_-}}{\\lVert\\mathbf{w}\\rVert}=\\frac{\\frac{1 - b}{1}-\\frac{1 - b}{-1}}{\\lVert\\mathbf{w}\\rVert}=\\frac{1 - b+b+1}{\\lVert\\mathbf{w}\\rVert}=\\frac{2}{\\lVert\\mathbf{w}\\rVert}$$\n",
    "где $\\mathbf{x_+}$ &ndash; ближайшая точка с \"положительной\" стороны гиперплоскости, т.е. представитель положительного класса ($c_+ = 1$), а $\\mathbf{x_-}$ &ndash; ближайшая точка с \"отрицательной\" стороны гиперплоскости, т.е. отрицательный класс ($c_- = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281d7b1",
   "metadata": {},
   "source": [
    "Получается, чем меньше $\\lVert\\mathbf{w}\\rVert$, тем больше ширина полосы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb87e5",
   "metadata": {},
   "source": [
    "Таким образом, можно сформулировать задачу математически:\n",
    "$$\n",
    "\\left\\{\\begin{aligned} \n",
    "    & \\lVert\\mathbf{w}\\rVert^2\\rightarrow\\min &\\\\ \n",
    "    & M_i\\geqslant 1,&\\text{ где }i = 1,\\dots,K\n",
    "\\end{aligned}\\right. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc933825",
   "metadata": {},
   "source": [
    "### Случай линейно-неразделимой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247ef90",
   "metadata": {},
   "source": [
    "Если выборка линейно-неразделима, то, как ни крути, будут экземпляры какого-либо из классов, которые будут лежать не на \"своей\" стороне от гиперплоскости. Такое поведение будет означать, что не для всех экземпляров класса будет выполняться условие\n",
    "$$M_i \\geqslant 1, \\text{ где } i = 1, \\dots, K$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45bd38",
   "metadata": {},
   "source": [
    "Разрешим эту проблему, введя ошибку $\\xi_i$. Тогда условие на отступы может быть записано как:\n",
    "$$M_i \\geqslant 1 - \\xi_i, \\text{ где } i = 1, \\dots, K$$\n",
    "Очевидно, что $\\forall i\\in\\{1,\\dots,K\\} \\: \\xi_i \\rightarrow 0$, т.к. мы хотим минимизировать ошибку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4ccbf",
   "metadata": {},
   "source": [
    "Тогда задача будет записана как ($C$ &ndash; выбранный нами гиперпараметр):\n",
    "$$\n",
    "\\begin{array}{cccc}\n",
    "    \\left\\{\\begin{aligned} \n",
    "        & \\lVert\\mathbf{w}\\rVert^2+C\\cdot\\sum_{j=1}^{K}\\xi_j\\rightarrow\\min &\\\\ \n",
    "        & M_i\\geqslant 1-\\xi_i,&\\text{ где }i = 1,\\dots,K\\\\\n",
    "        & \\xi_i\\geqslant 0,&\\text{ где }i = 1,\\dots,K\n",
    "    \\end{aligned}\\right.\n",
    "    & \\Rightarrow &\n",
    "    \\left\\{\\begin{aligned} \n",
    "        & \\lVert\\mathbf{w}\\rVert^2+C\\cdot\\sum_{j=1}^{K}\\xi_j\\rightarrow\\min &\\\\ \n",
    "        & \\xi_i\\geqslant1-M_i,&\\text{ где }i = 1,\\dots,K\\\\\n",
    "        & \\xi_i\\geqslant 0,&\\text{ где }i = 1,\\dots,K\n",
    "    \\end{aligned}\\right.\n",
    "    & \\Rightarrow \\\\\n",
    "    & \\Rightarrow &\n",
    "    \\left\\{\\begin{aligned} \n",
    "        & \\lVert\\mathbf{w}\\rVert^2+C\\cdot\\sum_{j=1}^{K}\\xi_j\\rightarrow\\min &\\\\ \n",
    "        & \\xi_i=\\max(0,1-M_i),&\\text{ где }i = 1,\\dots,K\n",
    "    \\end{aligned}\\right.\n",
    "    & \\Rightarrow \\\\\n",
    "    & \\Rightarrow &\n",
    "    \\left\\{\\begin{aligned} \n",
    "        & \\lVert\\mathbf{w}\\rVert^2+C\\cdot\\sum_{j=1}^{K}\\xi_j\\rightarrow\\min &\\\\ \n",
    "        & \\xi_i=(1-M_i)_+,&\\text{ где }i = 1,\\dots,K\n",
    "    \\end{aligned}\\right.\n",
    "    & \\Rightarrow \\\\\n",
    "    & \\Rightarrow &\n",
    "    \\begin{aligned} \n",
    "        & C\\cdot\\sum_{j=1}^{K}(1-M_j)_++\\lVert\\mathbf{w}\\rVert^2\\rightarrow\\min\n",
    "    \\end{aligned}\n",
    "    & \\Rightarrow \\\\\n",
    "    & \\Rightarrow &\n",
    "    \\begin{aligned} \n",
    "        \\sum_{j=1}^{K}(1-M_j)_++\\frac{1}{C}\\lVert\\mathbf{w}\\rVert^2\\rightarrow\\min\n",
    "    \\end{aligned}\n",
    "    &\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09d39e",
   "metadata": {},
   "source": [
    "Итого, есть оптимизационная задача:\n",
    "$$\n",
    "\\sum_{j=1}^{K}(1-M_j)_++\\frac{1}{C}\\lVert\\mathbf{w}\\rVert^2\\rightarrow\\min\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60df75",
   "metadata": {},
   "source": [
    "Решать её привычными градиентными методами не получится, т.к. из-за наличия в составе функции $(1-M_j)_+$, график общей функции имеет \"острые углы\", в которых не существует производной"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dfb9c3",
   "metadata": {},
   "source": [
    "Но выполнение условий теоремы Куна-Таккера помогают свести эту задачу к поиску седловой точки функции Лагранжа (именно такой алгоритм реализован во многих библиотеках). При сведении нашей задачи к упомянутой ранее получаем полезные соотношения (следствия из необходимых условий седловой точки):\n",
    "$$\n",
    "\\left\\{\\begin{aligned} \n",
    "    & \\mathbf{w} = \\sum_{i=1}^{K}\\lambda_i \\cdot c_i \\cdot \\mathbf{x}_i \\\\\n",
    "    & 0 \\leqslant \\lambda_i \\leqslant C, &\\text{ где } i=1,...,K\n",
    "\\end{aligned}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe41a3",
   "metadata": {},
   "source": [
    "Получается, $\\mathbf{w}$ &ndash; линейная комбинация объектов из выборки. Таким образом:\n",
    "  * Если $\\lambda_i=0$, то $\\mathbf{x}_i$ не используется для вычисления $\\mathbf{w}$\n",
    "  * Если $\\lambda_i\\neq0$, то $\\mathbf{x}_i$ используется для вычисления $\\mathbf{w}$ и называется _**опорным вектором**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe7b27",
   "metadata": {},
   "source": [
    "Более подробно классифицируем объекты выборки по $\\lambda$, $\\xi$ и $M$:\n",
    "  * $\\lambda_i=0;\\xi_i=0;M_i\\geqslant1$ &ndash; неинформативный объект, лежащий за пределами полосы\n",
    "  * $0<\\lambda_i< C;\\xi_i=0;M_i=1$ &ndash; опорный объект, лежащий на границе полосы\n",
    "  * $\\lambda_i=C;\\xi_i>0;M_i\\leqslant1$ &ndash; ошибочный опорный объект, лежащий не в \"своей\" области"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756be0da",
   "metadata": {},
   "source": [
    "Если есть основания полагать, что выборка почти линейно разделима, и лишь объекты-выбросы классифицируются неверно, то можно применить фильтрацию выбросов. Сначала задача решается при некотором $C$, и из выборки удаляется небольшая доля объектов, имеющих наибольшую величину ошибки $\\xi_i$. После этого задача решается заново по усечённой выборке. Возможно, придётся проделать несколько таких итераций, пока оставшиеся объекты не окажутся линейно разделимыми"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8b2a5",
   "metadata": {},
   "source": [
    "### Ядра SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55573f",
   "metadata": {},
   "source": [
    "Существует ещё один подход к решению проблемы линейной неразделимости. Это переход от исходного пространства признаковых описаний объектов $X$ к новому пространству $H$ с помощью некоторого преобразования $\\psi : X \\rightarrow H$. Если пространство $H$ имеет достаточно высокую размерность, то можно надеяться, что в нём выборка окажется линейно разделимой. Такое пространство $H$ называется _**спрямляющим**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a492c0",
   "metadata": {},
   "source": [
    "Единственным отличием при решении задачи в пространстве $H$ будет замена скалярного произведения $\\mathbf{x}\\cdot \\mathbf{y}$, проводимого в $X$ на $\\psi(\\mathbf{x})\\cdot \\psi(\\mathbf{y})$, проводимое в $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e02890",
   "metadata": {},
   "source": [
    "Таким образом, на пространство $H$ накладывается условие о существовании в нём операции скалярного произведения. В частности, на роль $H$ подойдёт любое евклидово пространство, а в общем случае &ndash; и гильбертово"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659b445",
   "metadata": {},
   "source": [
    "Поскольку оптимизационная задача\n",
    "$$\n",
    "\\sum_{j=1}^{K}(1-M_j)_++\\frac{1}{C}\\lVert\\mathbf{w}\\rVert^2\\rightarrow\\min\n",
    "$$\n",
    "а конкретно функция\n",
    "$$\n",
    "(1-M_j)_+ = \\max(0, 1-с_j\\cdot(\\mathbf{w}\\cdot\\mathbf{x}_j + b))\n",
    "$$\n",
    "зависит только от скалярных произведений объектов, а не от их размерности или того, как они представлены, можно заменить скалярное произведение $\\mathbf{x} \\cdot \\mathbf{y}$ на ядро $K(\\mathbf{x}, \\mathbf{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526958e",
   "metadata": {},
   "source": [
    "_**Ядро**_ &ndash; это некая функция $K : X \\times X \\rightarrow \\mathbb{R}$, представимая в виде $K(\\mathbf{x}, \\mathbf{y}) = \\psi(\\mathbf{x})\\cdot\\psi(\\mathbf{y})$ при некотором отображении $\\psi : X \\rightarrow H$,\n",
    "где $H$ &ndash; пространство со скалярным произведением"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4067c",
   "metadata": {},
   "source": [
    "Ядром может быть не всякая функция, а только та, которая удовлетворяет теореме Мерсера:\n",
    "    \n",
    "Функция $K(\\mathbf{x}, \\mathbf{y})$ является ядром тогда и только тогда, когда она симметрична и неотрицательно определена, то есть:\n",
    "$$\n",
    "\\left\\{\\begin{aligned} \n",
    "    & K(\\mathbf{x}, \\mathbf{y}) = K(\\mathbf{y}, \\mathbf{x}) \\\\\n",
    "    & \\int_X\\int_XK(\\mathbf{x}, \\mathbf{y})g(\\mathbf{x})g(\\mathbf{y})d\\mathbf{x}d\\mathbf{y} \\geqslant 0 & \\forall g: X \\rightarrow \\mathbb{R}\n",
    "\\end{aligned}\\right.\n",
    "$$\n",
    "\n",
    "К счастью, класс функций, которые удовлетворяют этой теореме, довольно широк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e4b33",
   "metadata": {},
   "source": [
    "#### Линейное ядро (Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cdc54",
   "metadata": {},
   "source": [
    "<img src=\"https://qu4nt.github.io/sklearn-doc-es/_images/sphx_glr_plot_svm_kernels_001.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc80a70",
   "metadata": {},
   "source": [
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{y}) = \\mathbf{x} \\cdot \\mathbf{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d84dc6",
   "metadata": {},
   "source": [
    "#### Полиномиальное ядро (Polynomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edcacf",
   "metadata": {},
   "source": [
    "<img src=\"https://qu4nt.github.io/sklearn-doc-es/_images/sphx_glr_plot_svm_kernels_002.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8e10a",
   "metadata": {},
   "source": [
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{y}) = (\\gamma \\cdot \\mathbf{x} \\cdot \\mathbf{y} + r)^d\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605481f",
   "metadata": {},
   "source": [
    "#### Гауссовское (RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b91cf",
   "metadata": {},
   "source": [
    "<img src=\"https://qu4nt.github.io/sklearn-doc-es/_images/sphx_glr_plot_svm_kernels_003.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc8102",
   "metadata": {},
   "source": [
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{y}) = \\exp\\left(-\\gamma\\lVert\\mathbf{x} - \\mathbf{y}\\rVert^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a2752",
   "metadata": {},
   "source": [
    "#### Сигмоидальное (Sigmoig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757023a",
   "metadata": {},
   "source": [
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{y}) = \\tanh\\left(\\gamma\\mathbf{x} \\cdot \\mathbf{y} + r\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e558b9",
   "metadata": {},
   "source": [
    "## Программирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3449d9",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208af364",
   "metadata": {},
   "source": [
    "```Python\n",
    "class sklearn.svm.SVC(*, C, kernel, degree, gamma, coef0, ...)\n",
    "```\n",
    "\n",
    "* `C` &ndash; параметр регуляризации (ограничение на $\\lambda$), по умолчанию &ndash; `1.0`\n",
    "* `kernel` &ndash; ядро, по умолчанию &ndash; `rbf`\n",
    "* `degree` &ndash; степень, используемая для полиномиального ядра, по умолчанию &ndash; `3`\n",
    "* `gamma` &ndash; $\\gamma$, используемая для гауссовского, полиномиального и сигмоидального ядер\n",
    "* `coef0` &ndash; $r$, используемый в полиномиальном и сигмоидальном ядрах, по умолчанию &ndash; `0.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90dcb4",
   "metadata": {},
   "source": [
    "Помимо общего классификатора `sklearn.svm.SVC` библиотека предоставляет классификатор `sklearn.svm.LinearSVC`. Данный классификатор &ndash; более гибко настраиваемая реализация класса `sklearn.svm.SVC` с линейным ядром. Как написано в документации, использование этого классификатора оправдано, если:\n",
    "  * выборка линейно разделима (использование обычного `sklearn.svm.SVC` не предоставляет возможности более гибкой настройки)\n",
    "  * выборка имеет очень большой размер (алгоритм с линейным ядром считается намного быстрее, чем с нелинейным)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6b577",
   "metadata": {},
   "source": [
    "### Задача определения радиопульсара"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6af0f",
   "metadata": {},
   "source": [
    "<img src=\"https://minio.nplus1.ru/app-images/173414/21e042b955d6a65f1ef1694564a193bc.jpg\" alt=\"drawing\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67db2d",
   "metadata": {},
   "source": [
    "_**Радиопульсар**_ - космический источник радиоизлучения, приходящего на Землю в виде периодических всплесков (импульсов). Согласно доминирующей астрофизической модели, пульсары представляют собой вращающиеся нейтронные звёзды с магнитным полем, которое наклонено к оси вращения, что вызывает модуляцию приходящего на Землю излучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064570cf",
   "metadata": {},
   "source": [
    "Набор данных содержит 16259 ложных примеров, вызванных интерференцией или шумом, и 1639 реальных примеров радиопульсаров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcba0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = \"radiopulsars.csv\"\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/alexandrehsd/Predicting-Pulsar-Stars/master/pulsar_stars.csv\",\n",
    "    DATA_FILE_PATH)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5b1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE_PATH)\n",
    "df.columns = [\"IP Mean\",     \"IP Sd\",     \"IP Kurtosis\",     \"IP Skewness\", \n",
    "              \"DM-SNR Mean\", \"DM-SNR Sd\", \"DM-SNR Kurtosis\", \"DM-SNR Skewness\",\n",
    "              \"target_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e334a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"target_class\"], axis=1)\n",
    "y = df[\"target_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b772c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxplot(plot_number: int, column: str) -> None:\n",
    "    plt.subplot(4, 2, plot_number)\n",
    "    X.boxplot(column=column)\n",
    "\n",
    "plt.figure(figsize=(24,20))\n",
    "\n",
    "for i, column in enumerate(X.columns):\n",
    "    draw_boxplot(i + 1, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d80fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histplot(plot_number: int, column: str, n_bins: int) -> None:\n",
    "    plt.subplot(4, 2, plot_number)\n",
    "    fig = X[column].hist(bins=n_bins)\n",
    "    fig.set_xlabel(column)\n",
    "\n",
    "plt.figure(figsize=(24,20))\n",
    "\n",
    "for i, column in enumerate(X.columns):\n",
    "    draw_histplot(i + 1, column, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_clf = SVC()\n",
    "simple_clf.fit(X_train, y_train)\n",
    "f1_score(y_test, simple_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ebd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "\n",
    "linear_params = {\n",
    "    \"C\":      [1, 5, 10, 50, 100],\n",
    "    \"kernel\": [\"linear\"]\n",
    "}\n",
    "\n",
    "poly_params = {\n",
    "    \"C\":      [1, 5, 10, 50, 100],\n",
    "    \"kernel\": [\"poly\"],\n",
    "    \"degree\": np.arange(1, 6, 1),       # 1, ..., 5\n",
    "    \"gamma\":  [\"scale\", \"auto\"],\n",
    "    \"coef0\":  np.arange(-0.9, 1.2, 0.3) # -0.9, -0.6, ..., 0.6, 0.9\n",
    "}\n",
    "\n",
    "rbf_params = {\n",
    "    \"C\":      [1, 5, 10, 50, 100],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\":  [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "sigmoid_params = {\n",
    "    \"C\":      [1, 5, 10, 50, 100],\n",
    "    \"kernel\": [\"sigmoid\"],\n",
    "    \"gamma\":  [\"scale\", \"auto\"],\n",
    "    \"coef0\":  np.arange(-0.9, 1.2, 0.3) # -0.9, -0.6, ..., 0.6, 0.9\n",
    "}\n",
    "\n",
    "params = [\n",
    "    linear_params,\n",
    "    poly_params,\n",
    "    rbf_params,\n",
    "    sigmoid_params\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf,\n",
    "                           param_grid=params,\n",
    "                           scoring=\"f1\",\n",
    "                           n_jobs=8,\n",
    "                           verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6846059",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41669034",
   "metadata": {},
   "source": [
    "Наилучшие параметры `{'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4568d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, best_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cm = pd.DataFrame(data=confusion_matrix(y_test, simple_clf.predict(X_test)),\n",
    "                         columns=[\"Actual P\", \"Actual N\"], \n",
    "                         index=[\"Predict P\", \"Predict N\"])\n",
    "best_cm = pd.DataFrame(data=confusion_matrix(y_test, best_clf.predict(X_test)),\n",
    "                       columns=[\"Actual P\", \"Actual N\"], \n",
    "                       index=[\"Predict P\", \"Predict N\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d05611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(simple_cm, annot=True, fmt='d', cmap='YlGnBu')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc17436",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(best_cm, annot=True, fmt='d', cmap='YlGnBu')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da72a1",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc45a6",
   "metadata": {},
   "source": [
    "Преимущества SVM перед методом стохастического градиента и нейронными сетями:\n",
    "  * Задача выпуклого квадратичного программирования хорошо изучена и имеет единственное решение\n",
    "  * Метод опорных векторов эквивалентен двухслойной нейронной сети, где число нейронов на скрытом слое определяется автоматически как число опорных векторов\n",
    "  * Принцип оптимальной разделяющей гиперплоскости приводит к максимизации ширины разделяющей полосы, а следовательно, к более уверенной классификации\n",
    "\n",
    "Недостатки классического SVM:\n",
    "\n",
    "  * Неустойчивость к шуму: выбросы в исходных данных становятся опорными объектами-нарушителями и напрямую влияют на построение разделяющей гиперплоскости.\n",
    "  * Не описаны общие методы построения ядер и спрямляющих пространств, наиболее подходящих для конкретной задачи.\n",
    "  * Нет отбора признаков.\n",
    "  * Необходимо подбирать константу C при помощи кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda0887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
