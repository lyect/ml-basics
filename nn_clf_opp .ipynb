{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7271c7",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c345da",
   "metadata": {},
   "source": [
    "Нейронная сеть - система из \"нейронов\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344e06e",
   "metadata": {},
   "source": [
    "<img src=\"https://turingbotsoftware.com/blog/wp-content/uploads/2020/08/1024px-Neural_network.svg_-1.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66099838",
   "metadata": {},
   "source": [
    "Таким образом работает скрытый нейрон:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a362c3c",
   "metadata": {},
   "source": [
    "<img src=\"https://nishantmunjal.com/wp-content/uploads/2024/07/activation-fun.webp\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a49b3",
   "metadata": {},
   "source": [
    "То есть математическое выражение вида:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4282c",
   "metadata": {},
   "source": [
    "$$\n",
    "y = f\\left(b+\\sum_{i=1}^{n}x_i\\cdot w_i\\right)=f\\left(\\mathbf{w}^T\\mathbf{x}+b\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652715c",
   "metadata": {},
   "source": [
    "Учить нейронную сеть - прогонять через неё учебную выборку (всю или только часть), сравнивать полученные значения классов с исходными метками классов (функцию потерь $L$), а после, на основе вычисленного отклонения, обновлять веса нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b315ad18",
   "metadata": {},
   "source": [
    "Обновление весов происходит с использованием backpropagation (здесь $\\delta$ - ошибка со слоя, который при прямом проходе идёт за данным, для поледнего слоя это будет значение функции потерь):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67ef23",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    " w_i\n",
    " && = &&&w_i + \\delta\\cdot\\frac{\\partial y}{\\partial w_i} &= \\\\\n",
    " && = &&&w_i + \\delta\\cdot\\frac{\\partial f(\\Sigma(w_1, \\dots, w_n, x_1,\\dots, x_n, b))}{\\partial w_i}&=\\\\\n",
    " && = &&&w_i + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot\\frac{\\partial \\Sigma}{\\partial w_i}&=\\\\\n",
    " && = &&&w_i + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot x_i\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707c3fb",
   "metadata": {},
   "source": [
    "В матричной записи:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0048e6c",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    " \\mathbf{w}\n",
    " && = &&&\\mathbf{w} + \\delta\\cdot\\frac{\\partial y}{\\partial \\mathbf{w}} &= \\\\\n",
    " && = &&&\\mathbf{w} + \\delta\\cdot\\frac{\\partial f(\\Sigma(\\mathbf{w}, \\mathbf{x}, b))}{\\partial \\mathbf{w}}&=\\\\\n",
    " && = &&&\\mathbf{w} + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot\\frac{\\partial \\Sigma}{\\partial \\mathbf{w}}&=\\\\\n",
    " && = &&&\\mathbf{w} + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot \\frac{d(\\mathbf{w}^T\\mathbf{x}+b)}{\\mathbf{w}}&=\\\\\n",
    " && = &&&\\mathbf{w} + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot\n",
    " \\left(\n",
    "  \\frac{d\\mathbf{w}^T}{d\\mathbf{w}}\\mathbf{x} +\n",
    "  \\mathbf{w}^T\\frac{d\\mathbf{x}}{d\\mathbf{w}} +\n",
    "  \\frac{db}{d\\mathbf{w}}\n",
    " \\right)\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5451be1",
   "metadata": {},
   "source": [
    "Вспоминая матричное дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b544a3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{da}{d\\mathbf{x}}=\n",
    "\\begin{bmatrix} \n",
    "    \\frac{da}{dx_{1}} \\\\\n",
    "    \\frac{da}{dx_{2}} \\\\\n",
    "    \\vdots            \\\\\n",
    "    \\frac{da}{dx_{3}}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\frac{d\\mathbf{x}}{d\\mathbf{y}}=\n",
    "\\begin{bmatrix} \n",
    "    \\frac{dx_{1}}{dy_{1}} & \\frac{dx_{1}}{dy_{2}} & \\dots  & \\frac{dx_{1}}{dy_{n}} \\\\\n",
    "    \\frac{dx_{2}}{dy_{1}} & \\frac{dx_{2}}{dy_{2}} & \\dots  & \\frac{dx_{2}}{dy_{n}} \\\\\n",
    "    \\vdots                & \\vdots                & \\ddots & \\vdots \\\\\n",
    "    \\frac{dx_{n}}{dy_{1}} & \\frac{dx_{n}}{dy_{2}} & \\dots  & \\frac{dx_{n}}{dy_{n}}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\frac{d\\mathbf{x}^T}{d\\mathbf{x}}=\\frac{d\\mathbf{x}}{d\\mathbf{x}}=I\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403a045",
   "metadata": {},
   "source": [
    "Получаем, что"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da40512",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{w} = \\mathbf{w} + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot\n",
    " \\left(I\\mathbf{x} + \\mathbf{w}^T\\mathbb{0} + \\mathbf{0}\\right)\n",
    " =\\mathbf{w} + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot\\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb965266",
   "metadata": {},
   "source": [
    "Аналогично для bias:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12795c9b",
   "metadata": {},
   "source": [
    "$$\n",
    "b = b + \\delta\\cdot\\frac{\\partial y}{\\partial b} = b + \\delta\\cdot\\frac{\\partial f(\\Sigma(\\mathbf{w}, \\mathbf{x},b))}{\\partial b}=b + \\delta\\cdot\\frac{df}{d\\Sigma}\\cdot\\frac{\\partial \\Sigma}{\\partial b}=b + \\delta\\cdot\\frac{df}{d\\Sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e870a",
   "metadata": {},
   "source": [
    "Если хотим считать сразу для нескольких нейронов и/или нескольких $x$, то в выражениях получим тензоры, а не матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b1285",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import itertools\n",
    "import typing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./car_accidents/X_train.csv\")\n",
    "y_train = pd.read_csv(\"./car_accidents/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_x_columns = [\n",
    "    \"Id\",\n",
    "    \"accident_index\",\n",
    "    \"generic_make_model\"\n",
    "]\n",
    "useless_y_columns = [\n",
    "    \"Id\"\n",
    "]\n",
    "\n",
    "X_train.drop(useless_x_columns, axis=1, inplace=True)\n",
    "y_train.drop(useless_y_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_missing_values_frame(\n",
    "    frame:         pd.DataFrame,\n",
    "    digits:        int,\n",
    "    drop_leq_than: float = 0.0,\n",
    "    eps:           float = 1e-6\n",
    ") -> pd.DataFrame:\n",
    "    n_rows = frame.shape[0]\n",
    "\n",
    "    missing_values_count = (frame == -1).sum().sort_values(ascending=False)\n",
    "    missing_values_percent = missing_values_count.apply(lambda c: round(c / n_rows * 100, digits))\n",
    "    \n",
    "    almost_filled_columns = missing_values_percent[missing_values_percent >= (drop_leq_than + eps)].index\n",
    "    \n",
    "    almost_filled_columns_count = missing_values_count[almost_filled_columns]\n",
    "    almost_filled_columns_percent = missing_values_percent[almost_filled_columns]\n",
    "    \n",
    "    missing_values_frame = pd.concat([almost_filled_columns_count, almost_filled_columns_percent], axis=1)\n",
    "    missing_values_frame = missing_values_frame.rename(columns={0: \"missing_count\", 1: \"missing_%\"})\n",
    "    \n",
    "    return missing_values_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d51536",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_missing_values_frame(X_train, 1, 0.0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e32188",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_columns = [\n",
    "    \"junction_control\",\n",
    "    \"second_road_number\",\n",
    "    \"engine_capacity_cc\",\n",
    "    \"age_of_vehicle\",\n",
    "    \"casualty_distance_banding\",\n",
    "    \"casualty_home_area_type\"\n",
    "]\n",
    "X_train.drop(sparse_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827510fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_missing_values_frame(X_train, 1, 0.0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values_rows(\n",
    "    x: pd.DataFrame,\n",
    "    y: pd.DataFrame\n",
    ") -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    missing_values_rows_masks = [None] * x.shape[1]\n",
    "    for i, col in enumerate(x.columns):\n",
    "        missing_values_rows_masks[i] = (x[col] == -1)\n",
    "    missing_values_rows_mask = functools.reduce(lambda x1, x2: x1 | x2, missing_values_rows_masks)\n",
    "    x_updated = x[~missing_values_rows_mask].reset_index(drop=True)\n",
    "    y_updated = y[~missing_values_rows_mask].reset_index(drop=True)\n",
    "    return (x_updated, y_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = drop_missing_values_rows(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_missing_values_frame(X_train, 1, 0.0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1aa3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\n",
    "    \"local_authority_highway\"\n",
    "]\n",
    "\n",
    "le = LabelEncoder()\n",
    "for text_column in text_columns:\n",
    "    X_train[text_column] = le.fit_transform(X_train[text_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlating_columns(\n",
    "    frame:     pd.DataFrame,\n",
    "    threshold: float,\n",
    "    eps:       float = 1e-6\n",
    ") -> pd.DataFrame:\n",
    "    corr_pairs = X_train.corr().abs().unstack().sort_values(ascending=False)\n",
    "    self_corr_pairs_mask = (corr_pairs > 1 - eps) & (corr_pairs < 1 + eps)\n",
    "    high_corr_pairs_mask = corr_pairs >= threshold + eps\n",
    "    high_corr_pairs = [sorted(pair) for pair in corr_pairs[~self_corr_pairs_mask & high_corr_pairs_mask].index]\n",
    "    high_corr_pairs = list(a for a, _ in itertools.groupby(high_corr_pairs))\n",
    "    high_corr_df = corr_pairs[high_corr_pairs].to_frame(name=\"correlation\")\n",
    "    high_corr_df = high_corr_df.reset_index().rename(columns={\"level_0\": \"column_1\", \"level_1\": \"column_2\"})\n",
    "    return high_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_correlating_columns(X_train, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlating_columns = [\n",
    "    \"age_band_of_casualty\",\n",
    "    \"pedestrian_movement\"\n",
    "]\n",
    "X_train.drop(correlating_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5985816",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e723be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    \"age_of_casualty\"\n",
    "]\n",
    "\n",
    "X_train_nb = X_train.drop(numeric_columns, axis=1)\n",
    "y_train_nb = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CategoricalNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68470a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_cv(\n",
    "    x:       pd.DataFrame,\n",
    "    y:       pd.DataFrame,\n",
    "    k_folds: int\n",
    ") -> np.ndarray:\n",
    "    stratified_x = x.copy()\n",
    "    stratified_y = y.copy()\n",
    "    for col in stratified_x.columns:\n",
    "        vc = stratified_x[col].value_counts()\n",
    "        small_grouped_values = (vc[vc < k_folds]).index\n",
    "        small_grouped_rows_mask = stratified_x[col].isin(small_grouped_values)\n",
    "        stratified_x = stratified_x[~small_grouped_rows_mask]\n",
    "        stratified_y = stratified_y[~small_grouped_rows_mask]\n",
    "    stratified_x = stratified_x.reset_index(drop=True)\n",
    "    stratified_y = stratified_y.reset_index(drop=True)\n",
    "    \n",
    "    return cross_val_score(\n",
    "        clf,\n",
    "        stratified_x,\n",
    "        stratified_y.values.flatten(),\n",
    "        cv=k_folds,\n",
    "        scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_cv(X_train_nb, y_train_nb, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5674c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd25dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf = X_train.copy()\n",
    "y_train_rf = y_train.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ebba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sX_train_rf, sXt_train_rf, sy_train_rf, syt_train_rf = train_test_split(\n",
    "    X_train_rf,\n",
    "    y_train_rf,\n",
    "    random_state=1,\n",
    "    train_size=0.8,\n",
    "    stratify=y_train)\n",
    "\n",
    "clf.fit(sX_train_rf, sy_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcaf0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(sXt_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(syt_train_rf, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630286d",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gb = X_train.copy()\n",
    "y_train_gb = y_train.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(iterations=500,\n",
    "                         depth=10,\n",
    "                         learning_rate=0.9,\n",
    "                         loss_function='MultiClass',\n",
    "                         metric_period=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff899b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sX_train_gb, sXt_train_gb, sy_train_gb, syt_train_gb = train_test_split(\n",
    "    X_train_gb,\n",
    "    y_train_gb,\n",
    "    random_state=1,\n",
    "    train_size=0.8,\n",
    "    stratify=y_train)\n",
    "\n",
    "clf.fit(sX_train_gb, sy_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(sXt_train_gb).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(syt_train_gb, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370643b",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93126d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa399b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train.copy()\n",
    "y_train_nn = pd.get_dummies(y_train[\"casualty_severity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5386b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential()\n",
    "clf.add(Dense(16, input_shape=(X_train_nn.shape[1],), activation=\"relu\"))\n",
    "clf.add(Dense(12, activation=\"relu\"))\n",
    "clf.add(Dense(16, activation=\"relu\"))\n",
    "clf.add(Dense(y_train_nn.shape[1], activation=\"softmax\"))\n",
    "\n",
    "clf.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "sX_train_nn, sXt_train_nn, sy_train_nn, syt_train_nn = train_test_split(\n",
    "    X_train_nn,\n",
    "    y_train_nn,\n",
    "    random_state=1,\n",
    "    train_size=0.8,\n",
    "    stratify=y_train)\n",
    "\n",
    "clf.fit(\n",
    "    sX_train_nn,\n",
    "    sy_train_nn,\n",
    "    epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(sXt_train_nn).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(pd.Series(syt_train_nn.columns[np.where(syt_train_nn!=0)[1]]) - 1, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95671962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
